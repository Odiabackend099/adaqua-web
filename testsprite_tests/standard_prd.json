{
  "meta": {
    "project": "Adaqua Conversational Voice Assistant",
    "date": "2025-09-13",
    "prepared_by": "Generated by TestSprite"
  },
  "product_overview": "Adaqua Conversational Voice Assistant delivers a seamless, continuous voice interaction experience on the web, enabling users to engage in natural, hands-free conversations with an AI assistant through a minimalistic and responsive UI.",
  "core_goals": [
    "Enable one-click start and stop for voice conversations with the AI assistant.",
    "Support continuous, low-latency voice interaction loops without requiring repeated user inputs.",
    "Implement robust barge-in support to allow user interruption during assistant speech playback.",
    "Ensure all sensitive API keys and tokens remain secure on the server with no exposure to clients.",
    "Achieve cross-browser compatibility on latest Chrome and Edge browsers (Windows).",
    "Provide graceful fallback behavior when OpenAI API keys are unavailable, using stub streams for chat continuity.",
    "Implement accessibility best practices including keyboard navigability and ARIA labels.",
    "Deliver Windows-friendly development and smoke test scripts to streamline setup and verification."
  ],
  "key_features": [
    "Modern voice recording UI with animated wave visualization, pause/stop controls, and responsive design.",
    "Main voice orchestrator component integrating Web Speech API for speech-to-text with continuous listening and interim results.",
    "Server-side proxy APIs for TTS (Adaqua Brain API) and STT (OpenAI Whisper API) with error and fallback handling.",
    "Server-Sent Events (SSE) chat streaming API supporting real-time conversation exchange with OpenAI or a stub fallback.",
    "Automatic audio unlock on first user gesture to address browser autoplay policies.",
    "Four distinct UI states: Idle, Listening, Thinking, and Speaking with corresponding UI feedback (glowing orb, captions, animations).",
    "Barge-in functionality that stops audio playback within 300 ms upon detecting user speech during assistant response.",
    "Comprehensive error handling with user notifications for microphone access denial, TTS failures, SSE drops, and autoplay blocking.",
    "Environment-driven configuration for voice IDs, API URLs, and languages.",
    "PowerShell scripts for local development setup and smoke test automation."
  ],
  "user_flow_summary": [
    "User navigates to the /voice page and is presented with a simple interface displaying a glowing orb and mic controls.",
    "User clicks the mic button once to start the conversation, which unlocks audio and begins continuous speech recognition via Web Speech API.",
    "User speaks naturally; interim speech transcription appears in captions during speech.",
    "Upon speech end, recognized text is sent to the server chat API via SSE; UI transitions to Thinking state and then Speaking state as the assistant replies with synthesized voice via TTS API.",
    "Audio playback completes, and the system automatically resumes listening for the next user utterance without further clicks.",
    "If the user speaks while the assistant is still speaking, the audio playback immediately stops and the system switches back to speech recognition to capture the new input (barge-in).",
    "User clicks the stop (X) button at any time to halt audio and speech recognition, returning the UI to Idle state.",
    "Error states such as microphone denial, synthesis failures, or network drops present clear user guidance toast messages or captions."
  ],
  "validation_criteria": [
    "The TTS API returns playable audio within 3 seconds time-to-first-byte consistently (S1).",
    "Starting a conversation requires only a single click; subsequent interactions occur continuously with automatic looping and no user clicks needed (S2).",
    "Barge-in support stops playback and resumes recognition within 300 milliseconds of user speech input during assistant speaking (S3).",
    "No secret environment variables or tokens are exposed in client code or logs; .env files are gitignored (S4).",
    "The voice assistant functions correctly on latest Chrome and Edge browsers on Windows platforms (S5).",
    "Fallback stub streamed chat operates correctly with no OpenAI key, maintaining the conversation loop (S6).",
    "UI accessibility is ensured with keyboard focus on buttons and appropriate ARIA labels.",
    "Error messages display properly for microphone denial, TTS failures, SSE disconnects, and autoplay blocking."
  ],
  "code_summary": {
    "tech_stack": [
      "TypeScript",
      "Next.js",
      "React",
      "Web Speech API",
      "Web Audio API",
      "MediaRecorder",
      "Server-Sent Events (SSE)",
      "OpenAI Whisper API",
      "Adaqua Brain API",
      "PowerShell",
      "CSS3"
    ],
    "features": [
      {
        "name": "VoiceRecordingUI Component",
        "description": "New modern voice recording interface with animated wave visualization, pause/stop controls, and responsive design",
        "files": [
          "components/VoiceRecordingUI.tsx",
          "components/AudioWaveVisualization.tsx",
          "components/ControlPanel.tsx",
          "styles/voice-recording.css"
        ]
      },
      {
        "name": "VoiceUI Component",
        "description": "Main voice orchestrator component with Web Speech API integration, continuous conversation loop, and barge-in functionality",
        "files": [
          "components/VoiceUI.tsx",
          "pages/voice.tsx"
        ]
      },
      {
        "name": "Voice Assistant Legacy",
        "description": "Original voice assistant implementation with VAD and continuous listening",
        "files": [
          "components/VoiceAssistant.tsx",
          "components/VoiceCallUI.tsx",
          "components/VoiceOnlyUI.tsx"
        ]
      },
      {
        "name": "TTS Voice API",
        "description": "Server-side proxy to Adaqua Brain API for Nigerian voice synthesis with error handling",
        "files": [
          "pages/api/voice.js"
        ]
      },
      {
        "name": "STT Transcribe API",
        "description": "Server-side proxy to OpenAI Whisper API for speech-to-text with fallback handling",
        "files": [
          "pages/api/transcribe.js"
        ]
      },
      {
        "name": "Chat SSE API",
        "description": "Server-Sent Events chat proxy with OpenAI integration and stub fallback for continuous conversation",
        "files": [
          "pages/api/chat.ts"
        ]
      },
      {
        "name": "Audio Utilities",
        "description": "Audio unlock, playback, and barge-in support with browser autoplay handling",
        "files": [
          "lib/audio.ts"
        ]
      },
      {
        "name": "Voice Styling",
        "description": "Minimal UI with glowing orb, voice state indicators, and responsive design",
        "files": [
          "styles/voice.css",
          "pages/_app.tsx"
        ]
      },
      {
        "name": "Development Scripts",
        "description": "PowerShell scripts for development setup and smoke testing",
        "files": [
          "scripts/dev.ps1",
          "scripts/smoke.ps1",
          "scripts/smoke-test.ps1",
          "scripts/smoke-voice.ps1"
        ]
      },
      {
        "name": "Documentation",
        "description": "Comprehensive documentation including PRD, tasks, and voice recording UI guide",
        "files": [
          "docs/PRD.md",
          "docs/TASKS.md",
          "docs/SUCCESS-CHECKLIST.md",
          "docs/VOICE-RECORDING-UI.md",
          "README.md"
        ]
      },
      {
        "name": "TestSprite Tests",
        "description": "Automated test suite with frontend and backend test plans",
        "files": [
          "testsprite_tests/testsprite_frontend_test_plan.json",
          "testsprite_tests/TC001_Start_Conversation_Flow_with_Single_Click.py",
          "testsprite_tests/TC002_Continuous_Conversation_Loop_Functionality.py",
          "testsprite_tests/TC003_Barge_In_Support_Interrupts_Audio_Playback_and_Restarts_Recognition.py",
          "testsprite_tests/TC004_Stop_Conversation_Sets_UI_to_Idle_and_Stops_Audio__Recognition.py",
          "testsprite_tests/TC005_Mic_Access_Denied_Error_Handling.py",
          "testsprite_tests/TC006_TTS_Proxy_Returns_Playable_Audio_within_Performance_Requirements.py",
          "testsprite_tests/TC007_Fallback_SSE_Chat_Stream_Works_without_OpenAI_API_Key.py",
          "testsprite_tests/TC009_UI_State_Transitions_Follow_Correct_Sequence.py",
          "testsprite_tests/TC010_Ensure_No_Secret_Environment_Variables_Exposed_in_Client.py",
          "testsprite_tests/TC011_Development_PowerShell_Setup_Script_Executes_Successfully.py",
          "testsprite_tests/TC012_Smoke_Test_PowerShell_Script_Validates_Backend_TTS_Endpoint.py",
          "testsprite_tests/TC013_Unknown_Endpoint_Error_Handling_on_TTS_Proxy_API.py",
          "testsprite_tests/TC014_Captions_Update_Correctly_with_Interim_and_Final_Recognition_Results.py",
          "testsprite_tests/TC015_Voice_UI_Accessibility___ARIA_Labels_and_Keyboard_Controls.py",
          "testsprite_tests/TC016_Server_Sent_Events_Chat_API_Handles_SSE_Disconnects_Gracefully.py"
        ]
      }
    ]
  }
}
